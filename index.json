[{"authors":["admin"],"categories":null,"content":"I am Ph.D. Candidate in Shanghai Jiao Tong University, under the supervision of Kai Yu and Yanmin Qian. My research interests include deep learning based approaches for speaker recognition, speaker diarization and voice activity detection.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://wsstriving.github.io/author/shuai-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shuai-wang/","section":"authors","summary":"I am Ph.D. Candidate in Shanghai Jiao Tong University, under the supervision of Kai Yu and Yanmin Qian. My research interests include deep learning based approaches for speaker recognition, speaker diarization and voice activity detection.","tags":null,"title":"Shuai Wang","type":"authors"},{"authors":[],"categories":["blog"],"content":" 不论是机器学习的分类问题，或者具体到说话人识别中，都需要对模型的性能指标进行评判，这就牵涉到性能度量指标的问题，常见的有几种，长得比较相似，也容易弄混，在这里加以阐述区分\n 1. 错误率与精度 错误率Err. Rate 是分类错误的样本数占样本总数的比例，精度Acc. Rate 是分类正确的样本数占样本总数的比例\n$$ \\begin{align} Err. Rate \u0026amp;= \\frac{1}{m}\\sum_{i=1}^{m}\\mathcal{I}(f(x_i)=y_i) \\\nAcc. Rate \u0026amp;= 1-Err. Rate \\end{align} $$\n2. 查准率与查全率  True Positive （真正,TP）被模型预测为正的正样本； True Negative（真负 , TN） 被模型预测为负的负样本； False Positive （假正, FP）被模型预测为正的负样本； False Negative（假负 , FN）被模型预测为负的正样本；  查准率 P=TP／TP+FP, 关注预测为正的样本里多少是真的正例。 查全率 R=TP／TP+FN, 关注是不是所有正样本都被正确分类。 当查准率等于查全率时候得到BEP(Break-Even Point):　BEP=P=R\nBEP 的度量太简单，因此又定义了F1 score：\n$$ F1=\\frac{2\\times P \\times R}{P+R}=\\frac{2 \\times TP}{#samples + TP-TN} $$\nF1 score 是查准率和查全率的调和平均数。\n3. 错误拒绝率和错误接受率 首先给出如下定义\n True Positive Rate　TPR = TP /（TP + FN） 正样本预测正确数 / 正样本实际数 True Negative Rate TNR = TN /（TN + FP） 负样本预测正确数 / 负样本实际数 False Positive Rate FPR = FP /（TN + FP） 负样本预测错误数 /负样本实际数 False Negative Rate FNR = FN /（TP + FN） 正样本预测错误数 / 正样本实际数  在说话人识别常用的评测标准中，FPR又称为FAR(False Accept Rate错误接受率),FNR又称为FRR(False Reject Rate错误拒绝率1)，\n最重要的一项评价指标EER(Equal Error Rate) 定义为EER=FAR=FRR\n在FAR 和FRR的基础上，定义了最小检测代价(minDCF) $$DCF = C_{FRR} \\times FRR \\times P_{target} + C_{FAR} \\times FAR \\times (1 − P_{target})$$ minDCF 为DCF的最小值。\n$$P_{target}$$是先验概率\n  有的文献里称FAR为虚警率，FRR为漏警率。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":1593082555,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593082555,"objectID":"2c57f35570e77cd35157c4ed3e58beb4","permalink":"https://wsstriving.github.io/post/eval_metrics/","publishdate":"2020-06-25T18:55:55+08:00","relpermalink":"/post/eval_metrics/","section":"post","summary":"不论是机器学习的分类问题，或者具体到说话人识别中，都需要对模型的性能指标进行评判，这就牵涉到性能度量指标的问题，常见的有几种，长得比较相似，也容易弄混，在这里加以阐述区分\n 1. 错误率与精度 错误率Err. Rate 是分类错误的样本数占样本总数的比例，精度Acc. Rate 是分类正确的样本数占样本总数的比例\n$$ \\begin{align} Err. Rate \u0026amp;= \\frac{1}{m}\\sum_{i=1}^{m}\\mathcal{I}(f(x_i)=y_i) \\\nAcc. Rate \u0026amp;= 1-Err. Rate \\end{align} $$\n2. 查准率与查全率  True Positive （真正,TP）被模型预测为正的正样本； True Negative（真负 , TN） 被模型预测为负的负样本； False Positive （假正, FP）被模型预测为正的负样本； False Negative（假负 , FN）被模型预测为负的正样本；  查准率 P=TP／TP+FP, 关注预测为正的样本里多少是真的正例。 查全率 R=TP／TP+FN, 关注是不是所有正样本都被正确分类。 当查准率等于查全率时候得到BEP(Break-Even Point):　BEP=P=R","tags":["Chinese"],"title":"常用性能度量指标","type":"post"},{"authors":["Shuai Wang","Yanmin Qian and Kai Yu"],"categories":[],"content":"","date":1498384882,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498384882,"objectID":"49daf81e9b3979471a1960974d3c31d0","permalink":"https://wsstriving.github.io/publication/2017-interspeech/","publishdate":"2020-06-25T18:01:22+08:00","relpermalink":"/publication/2017-interspeech/","section":"publication","summary":"summary","tags":[],"title":"What Does the Speaker Embedding Encode?","type":"publication"}]