<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Academic</title>
    <link>https://wsstriving.github.io/</link>
      <atom:link href="https://wsstriving.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Academic</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 25 Jun 2020 18:55:55 +0800</lastBuildDate>
    <image>
      <url>https://wsstriving.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Academic</title>
      <link>https://wsstriving.github.io/</link>
    </image>
    
    <item>
      <title>常用性能度量指标</title>
      <link>https://wsstriving.github.io/post/eval_metrics/</link>
      <pubDate>Thu, 25 Jun 2020 18:55:55 +0800</pubDate>
      <guid>https://wsstriving.github.io/post/eval_metrics/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;不论是机器学习的分类问题，或者具体到说话人识别中，都需要对模型的性能指标进行评判，这就牵涉到性能度量指标的问题，常见的有几种，长得比较相似，也容易弄混，在这里加以阐述区分&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;1-错误率与精度&#34;&gt;1. 错误率与精度&lt;/h2&gt;
&lt;p&gt;错误率Err. Rate 是分类错误的样本数占样本总数的比例，精度Acc. Rate 是分类正确的样本数占样本总数的比例&lt;/p&gt;
&lt;p&gt;$$
Err. Rate = \frac{1}{m}\sum_{i=1}^{m}\mathcal{I}(f(x_i)=y_i)
$$&lt;/p&gt;
&lt;p&gt;$$
Acc. Rate = 1-Err. Rate
$$&lt;/p&gt;
&lt;h2 id=&#34;2-查准率与查全率&#34;&gt;2. 查准率与查全率&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;True Positive （真正,TP）被模型预测为正的正样本；&lt;/li&gt;
&lt;li&gt;True Negative（真负 , TN） 被模型预测为负的负样本；&lt;/li&gt;
&lt;li&gt;False Positive （假正, FP）被模型预测为正的负样本；&lt;/li&gt;
&lt;li&gt;False Negative（假负 , FN）被模型预测为负的正样本；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;查准率 P=TP／TP+FP, 关注预测为正的样本里多少是真的正例。
查全率 R=TP／TP+FN, 关注是不是所有正样本都被正确分类。
当查准率等于查全率时候得到BEP(Break-Even Point):　BEP=P=R&lt;/p&gt;
&lt;p&gt;BEP 的度量太简单，因此又定义了F1 score：&lt;/p&gt;
&lt;p&gt;$$
F1=\frac{2\times P \times R}{P+R}=\frac{2 \times TP}{#samples + TP-TN}
$$&lt;/p&gt;
&lt;p&gt;F1 score 是查准率和查全率的调和平均数。&lt;/p&gt;
&lt;h2 id=&#34;3-错误拒绝率和错误接受率&#34;&gt;3. 错误拒绝率和错误接受率&lt;/h2&gt;
&lt;p&gt;首先给出如下定义&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;True Positive Rate　TPR = TP /（TP + FN）
　正样本预测正确数 / 正样本实际数&lt;/li&gt;
&lt;li&gt;True Negative Rate TNR = TN /（TN + FP）
　负样本预测正确数 / 负样本实际数&lt;/li&gt;
&lt;li&gt;False Positive Rate FPR = FP /（TN + FP）
负样本预测错误数 /负样本实际数&lt;/li&gt;
&lt;li&gt;False Negative Rate FNR = FN /（TP + FN）
正样本预测错误数 / 正样本实际数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在说话人识别常用的评测标准中，FPR又称为FAR(False Accept Rate错误接受率),FNR又称为FRR(False Reject Rate错误拒绝率&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;)，&lt;/p&gt;
&lt;p&gt;最重要的一项评价指标EER(Equal Error Rate) 定义为EER=FAR=FRR&lt;/p&gt;
&lt;p&gt;在FAR 和FRR的基础上，定义了最小检测代价(minDCF)
$DCF = C_{FRR} \times FRR \times P_{target} + C_{FAR} \times FAR \times (1 − P_{target})$
minDCF 为DCF的最小值。&lt;/p&gt;
&lt;p&gt;$P_{target}$是先验概率&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;有的文献里称FAR为虚警率，FRR为漏警率。 &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>What Does the Speaker Embedding Encode?</title>
      <link>https://wsstriving.github.io/publication/2017-interspeech/</link>
      <pubDate>Sun, 25 Jun 2017 18:01:22 +0800</pubDate>
      <guid>https://wsstriving.github.io/publication/2017-interspeech/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
